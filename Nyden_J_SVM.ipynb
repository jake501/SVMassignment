{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW76pPxuXJ6V",
        "outputId": "5cd31af3-d405-4cc2-c1c3-c236d9671de4"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "#load mice protein dataset from OpenML\n",
        "mice = fetch_openml(name='miceprotein', version=4, as_frame=True)\n",
        "list(mice.frame.columns)\n",
        "print(mice.details)\n",
        "mice.frame.describe()\n",
        "\n",
        "\n",
        "# Import required libraries\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "# Import model to divide data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "target_column = ['class']\n",
        "#derive the list of predictor column id's\n",
        "predictors = list(set(list(mice.frame.columns))-set(target_column))\n",
        "#standardize the predictors by diividing by the maximum\n",
        "mice.frame[predictors] = mice.frame[predictors]/mice.frame[predictors].max()\n",
        "#provide summary statistics for the dataframe\n",
        "mice.frame.describe().transpose()\n",
        "\n",
        "#Get rid of any rown with NA's\n",
        "mice.frame = mice.frame.dropna()\n",
        "\n",
        "#the input data\n",
        "X = mice.frame[predictors].values\n",
        "#the output data\n",
        "y = mice.frame[target_column].values\n",
        "\n",
        "#we encode target classes from strings to numbers as neural networks cannot require all numerical inputs and outputs\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "#divide data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
        "print(X_train.shape); print(X_test.shape)\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "svm_model = svm.SVC(decision_function_shape='ovr')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "#We predict the training set\n",
        "predict_train = svm_model.predict(X_train)\n",
        "#we predict the test set\n",
        "predict_test = svm_model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "print('Training accuracy')\n",
        "#we report the confusion matrix for the training set\n",
        "print(confusion_matrix(y_train,predict_train))\n",
        "#we report various accuracy statistics for the training set\n",
        "print(classification_report(y_train,predict_train))\n",
        "\n",
        "print('Testing accuracy')\n",
        "#we report the confusion matrix for the test set\n",
        "print(confusion_matrix(y_test,predict_test))\n",
        "#we report various accuracy statistics for the test set\n",
        "print(classification_report(y_test,predict_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '40966', 'name': 'MiceProtein', 'version': '4', 'description_version': '1', 'format': 'ARFF', 'upload_date': '2017-11-08T16:00:15', 'licence': 'Public', 'url': 'https://api.openml.org/data/v1/download/17928620/MiceProtein.arff', 'parquet_url': 'https://openml1.win.tue.nl/datasets/0004/40966/dataset_40966.pq', 'file_id': '17928620', 'default_target_attribute': 'class', 'row_id_attribute': 'MouseID', 'ignore_attribute': ['Genotype', 'Treatment', 'Behavior'], 'tag': ['Economics', 'OpenML-CC18', 'study_135', 'study_98', 'study_99'], 'visibility': 'public', 'minio_url': 'https://openml1.win.tue.nl/datasets/0004/40966/dataset_40966.pq', 'status': 'active', 'processing_date': '2018-10-04 00:49:58', 'md5_checksum': '3c479a6885bfa0438971388283a1ce32'}\n",
            "(386, 77)\n",
            "(166, 77)\n",
            "Training accuracy\n",
            "[[32  0  0  0  0  0  0  0]\n",
            " [ 0 56  0  0  0  0  0  0]\n",
            " [ 0  0 45  0  0  0  0  0]\n",
            " [ 0  0  0 53  0  0  0  0]\n",
            " [ 2  0  0  0 63  0  0  0]\n",
            " [ 0  0  0  0  0 48  0  0]\n",
            " [ 0  0  7  0  0  0 26  0]\n",
            " [ 0  0  0  0  0  0  0 54]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97        32\n",
            "           1       1.00      1.00      1.00        56\n",
            "           2       0.87      1.00      0.93        45\n",
            "           3       1.00      1.00      1.00        53\n",
            "           4       1.00      0.97      0.98        65\n",
            "           5       1.00      1.00      1.00        48\n",
            "           6       1.00      0.79      0.88        33\n",
            "           7       1.00      1.00      1.00        54\n",
            "\n",
            "    accuracy                           0.98       386\n",
            "   macro avg       0.98      0.97      0.97       386\n",
            "weighted avg       0.98      0.98      0.98       386\n",
            "\n",
            "Testing accuracy\n",
            "[[13  0  0  0  0  0  0  0]\n",
            " [ 0 19  0  0  0  0  0  0]\n",
            " [ 0  0 15  0  0  0  0  0]\n",
            " [ 0  0  0 22  0  0  0  0]\n",
            " [ 1  0  0  0 24  0  0  0]\n",
            " [ 0  0  0  0  0 27  0  0]\n",
            " [ 0  0  5  0  0  0 22  0]\n",
            " [ 0  0  0  0  0  0  0 18]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96        13\n",
            "           1       1.00      1.00      1.00        19\n",
            "           2       0.75      1.00      0.86        15\n",
            "           3       1.00      1.00      1.00        22\n",
            "           4       1.00      0.96      0.98        25\n",
            "           5       1.00      1.00      1.00        27\n",
            "           6       1.00      0.81      0.90        27\n",
            "           7       1.00      1.00      1.00        18\n",
            "\n",
            "    accuracy                           0.96       166\n",
            "   macro avg       0.96      0.97      0.96       166\n",
            "weighted avg       0.97      0.96      0.96       166\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J0H78P0JX0lr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}